// src/core/histogram.ts
import fg from 'fast-glob';
import fs from 'fs-extra';
import { colord, extend } from 'colord';
import namesPlugin from 'colord/plugins/names';
import { TokenMeta, TokenType } from '../types';

extend([namesPlugin]);

// --- 1. å®šä¹‰æ¢æµ‹å™¨æ¥å£ (Detector Interface) ---
interface StyleDetector {
  type: TokenType;
  regex: RegExp;
  // å¯é€‰ï¼šå½’ä¸€åŒ–å‡½æ•° (ä¾‹å¦‚æŠŠ p-4 å’Œ pt-4 éƒ½å½’ä¸º spacing: 4)
  normalize?: (match: string) => string | null; 
}

// --- 2. é…ç½®æ¢æµ‹è§„åˆ™ (The Rules) ---
const DETECTORS: StyleDetector[] = [
  {
    type: 'color',
    // åŒ¹é… Hex, RGB, RGBA
    regex: /#([0-9a-f]{3}){1,2}\b|rgb\(\s*\d+\s*,\s*\d+\s*,\s*\d+\s*\)|rgba\([^)]+\)/gi,
    normalize: (val) => {
      const c = colord(val);
      return c.isValid() ? c.toHex() : null;
    }
  },
  {
    type: 'spacing',
    // ğŸŒŸ é‡ç‚¹: åŒæ—¶æ•è· Tailwind Utility å’Œ Raw CSS Unit
    // æ•è·: p-4, m-2, gap-x-4, w-full, h-10
    // æ•è·: 16px, 1rem
    regex: /\b([pmWH][tbrlxy]?|gap(-[xy])?|space-[xy])-([0-9.]+|px)\b|\b\d+(\.\d+)?(px|rem|em)\b/g,
    normalize: (val) => val // æš‚æ—¶ç›´æ¥ç»Ÿè®¡åŸå§‹å€¼ï¼Œçœ‹å“ªä¸ªç”¨å¾—å¤š
  },
  {
    type: 'radius',
    // æ•è·: rounded-lg, rounded-md, rounded-tr-xl
    // æ•è·: 8px (å¦‚æœåœ¨ border-radius ä¸Šä¸‹æ–‡æ¯”è¾ƒéš¾åŒºåˆ†ï¼Œè¿™é‡Œå…ˆç²—ç•¥æ•è·)
    regex: /\brounded(-[tbrl][r l]?)?-(sm|md|lg|xl|2xl|3xl|full|none)\b/g,
    normalize: (val) => val
  },
  {
    type: 'typography',
    // æ•è·: text-xl, text-sm, font-bold
    regex: /\b(text-(xs|sm|base|lg|xl|2xl|3xl|4xl|5xl)|font-(thin|light|normal|medium|bold|black))\b/g,
    normalize: (val) => val
  },
  {
     type: 'shadow',
     regex: /\bshadow-(sm|md|lg|xl|2xl|inner|none)\b/g,
     normalize: (val) => val
  }
];

// --- 3. é€šç”¨æ‰«æé€»è¾‘ ---
export async function scanShadowTokens(rootPath: string): Promise<TokenMeta[]> {
  // å­˜å‚¨ç»“æ„: { 'color': { '#fff': 10 }, 'spacing': { 'p-4': 50 } }
  const stats: Record<string, Map<string, number>> = {};
  
  // åˆå§‹åŒ– Map
  DETECTORS.forEach(d => stats[d.type] = new Map());

  const files = await fg([`${rootPath}/src/**/*.{tsx,jsx,css,scss,ts}`], { 
    ignore: ['**/node_modules/**', '**/.fence/**'] 
  });

  for (const file of files) {
    const content = await fs.readFile(file, 'utf-8');

    // éå†æ‰€æœ‰æ¢æµ‹å™¨
    DETECTORS.forEach(detector => {
      const matches = content.match(detector.regex);
      if (matches) {
        matches.forEach(raw => {
          const normalized = detector.normalize ? detector.normalize(raw) : raw;
          if (normalized) {
            const map = stats[detector.type];
            map.set(normalized, (map.get(normalized) || 0) + 1);
          }
        });
      }
    });
  }

  // --- 4. æ‰å¹³åŒ–ç»“æœ ---
  const results: TokenMeta[] = [];

  Object.entries(stats).forEach(([type, map]) => {
    // å¯¹æ¯ç§ç±»å‹ï¼Œå– Top 10 (é¿å…å™ªéŸ³å¤ªå¤š)
    const topEntries = Array.from(map.entries())
      .sort((a, b) => b[1] - a[1]) // é™åº
      .slice(0, 10); // åªå–å‰10å
    
    topEntries.forEach(([value, count]) => {
      results.push({
        type: type as TokenType,
        value,
        count,
        source: 'scan'
      });
    });
  });

  // å…¨å±€å†æŒ‰é¢‘ç‡æ’ä¸€æ¬¡åºï¼Œè®©é«˜é¢‘çš„æ’å‰é¢
  return results.sort((a, b) => b.count - a.count);
}